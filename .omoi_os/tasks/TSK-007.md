---
id: TSK-007
title: Implement MemoryMerger for merging clusters
status: pending
created: 2025-01-08
parent_ticket: TKT-002
estimate: M
type: implementation
dependencies:
  depends_on: [TSK-002, TSK-003, TSK-006]
  blocks: []
---

# TSK-007: Implement MemoryMerger for merging clusters

## Objective

Implement the memory merger that combines similar memories into consolidated entries.

## Context

Once clusters of similar memories are identified, they need to be merged into single consolidated memories. This component handles content combination, metadata merging, and source memory tracking.

## Deliverables

- `backend/omoi_os/services/consolidation/memory_merger.py` - MemoryMerger class

## Implementation Notes

```python
# omoi_os/services/consolidation/memory_merger.py
from typing import List
from sqlalchemy.orm import Session

from omoi_os.models.task_memory import TaskMemory
from omoi_os.services.embedding import EmbeddingService
from omoi_os.services.consolidation.similarity_detector import MemoryCluster

class MemoryMerger:
    def __init__(self, embedding_service: EmbeddingService):
        self.embedding_service = embedding_service

    async def merge_cluster(
        self,
        session: Session,
        cluster: MemoryCluster,
    ) -> str:
        """
        Merge a cluster into single consolidated memory.

        Strategy:
        1. Select representative (highest reused_count)
        2. Combine content from all memories
        3. Merge tags and file links
        4. Generate new embedding
        5. Mark sources as duplicate
        6. Create consolidated memory

        Returns ID of new consolidated memory.
        """
        # Get source memories
        source_memories = [
            session.get(TaskMemory, mid) for mid in cluster.memory_ids
        ]

        # Select representative
        representative = max(source_memories, key=lambda m: m.reused_count)

        # Build consolidated content
        content = self._build_merged_content(source_memories)

        # Combine metadata
        all_tags = self._merge_tags(source_memories)
        all_files = self._merge_file_links(source_memories, session)

        # Generate embedding
        embedding = self.embedding_service.generate_embedding(content)

        # Create consolidated memory
        consolidated = TaskMemory(
            task_id=representative.task_id,
            execution_summary=content,
            memory_type="consolidated",
            context_embedding=embedding,
            goal=self._merge_field(source_memories, "goal"),
            result=self._merge_field(source_memories, "result"),
            tags=list(all_tags),
            consolidated_from=[str(m.id) for m in source_memories],
            consolidated_at=utc_now(),
            success=any(m.success for m in source_memories),
        )

        session.add(consolidated)
        session.flush()

        # Mark sources as duplicate
        for mem in source_memories:
            mem.is_duplicate = True
            mem.duplicate_of = str(consolidated.id)

        return str(consolidated.id)

    def _build_merged_content(self, memories: List[TaskMemory]) -> str:
        """Build consolidated content from memories."""
        sections = []
        for i, mem in enumerate(memories, 1):
            sections.append(f"Source {i}: {mem.execution_summary}")
        return "\n\n".join(sections)

    def _merge_tags(self, memories: List[TaskMemory]) -> set:
        """Merge and deduplicate tags."""
        tags = set()
        for mem in memories:
            if mem.tags:
                tags.update(mem.tags)
        return tags
```

## Acceptance Criteria

- [ ] MemoryMerger class with merge_cluster() method
- [ ] Selects representative by reused_count
- [ ] Combines content with clear separators
- [ ] Merges tags (union, deduplicated)
- [ ] Preserves all file links from sources
- [ ] Generates new embedding for consolidated memory
- [ ] Marks source memories as duplicate
- [ ] Sets consolidated_from and consolidated_at
- [ ] Unit tests for various cluster sizes

## Dependencies

**Depends On**: TSK-002, TSK-003, TSK-006
**Blocks**: None

## Estimate

**Size**: M (2-4 hours)
