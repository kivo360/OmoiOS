---
id: TSK-001
title: Create ConsolidatedMemory SQLAlchemy model
status: pending
ticket_id: TKT-001
parent_ticket: TKT-001
estimate: M
type: implementation
dependencies:
  depends_on: []
  blocks:
    - TSK-004
---

# TSK-001: Create ConsolidatedMemory SQLAlchemy model

## Objective

Create the ConsolidatedMemory SQLAlchemy model representing consolidated and synthesized memories in the Agent Memory Consolidation System.

## Context

The ConsolidatedMemory model stores higher-level knowledge extracted from raw task memories. It supports three abstraction levels (1=merged, 2=pattern, 3=principle) and maintains full lineage to source memories.

## Deliverables

- [ ] `backend/omoi_os/models/consolidated_memory.py` - ConsolidatedMemory model class

## Implementation Notes

```python
# backend/omoi_os/models/consolidated_memory.py
from datetime import datetime, timezone
from typing import TYPE_CHECKING, Optional
from uuid import uuid4

from sqlalchemy import Boolean, DateTime, Float, Integer, String, Text, Enum as SQLEnum
from sqlalchemy.dialects.postgresql import ARRAY as PG_ARRAY, JSONB, VECTOR
from sqlalchemy.orm import Mapped, mapped_column

from omoi_os.models.base import Base

if TYPE_CHECKING:
    from omoi_os.models.project import Project

class AbstractionLevel(str, SQLEnum):
    MERGED = "1"      # Merged raw memories
    PATTERN = "2"     # Extracted pattern
    PRINCIPLE = "3"   # Abstract principle

class PatternType(str, SQLEnum):
    SUCCESS = "success"
    FAILURE = "failure"
    DECISION = "decision"
    WORKFLOW = "workflow"
    GOTCHA = "gotcha"

class ConsolidatedMemory(Base):
    """Consolidated and synthesized memories from raw task executions."""

    __tablename__ = "consolidated_memories"

    id: Mapped[str] = mapped_column(
        String, primary_key=True, default=lambda: str(uuid4())
    )
    project_id: Mapped[str] = mapped_column(
        String, nullable=False, index=True
    )

    # Content
    content: Mapped[str] = mapped_column(Text, nullable=False)
    memory_type: Mapped[str] = mapped_column(
        String(50), nullable=False, index=True
    )  # Uses existing MemoryType enum
    abstraction_level: Mapped[int] = mapped_column(
        Integer, nullable=False, index=True
    )  # 1=merged, 2=pattern, 3=principle

    # Context
    pattern_type: Mapped[Optional[str]] = mapped_column(
        String(50), nullable=True
    )
    confidence_score: Mapped[Optional[float]] = mapped_column(
        Float, nullable=True
    )
    source_memory_ids: Mapped[list[str]] = mapped_column(
        PG_ARRAY(String), nullable=False
    )

    # Embedding for semantic search
    embedding: Mapped[Optional[list[float]]] = mapped_column(
        VECTOR(3072), nullable=True
    )

    # Metadata
    tags: Mapped[Optional[list[str]]] = mapped_column(
        PG_ARRAY(String(50)), nullable=True
    )
    consolidation_method: Mapped[Optional[str]] = mapped_column(
        String(100), nullable=True
    )  # llm, heuristic, hybrid
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), nullable=False, default=lambda: datetime.now(timezone.utc)
    )
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), nullable=False, default=lambda: datetime.now(timezone.utc), onupdate=lambda: datetime.now(timezone.utc)
    )
    consolidated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), nullable=False, default=lambda: datetime.now(timezone.utc)
    )

    # Statistics
    source_count: Mapped[int] = mapped_column(Integer, nullable=False)
    reuse_count: Mapped[int] = mapped_column(Integer, nullable=False, default=0)

    def to_dict(self) -> dict:
        """Convert to dictionary for API responses."""
        return {
            "id": self.id,
            "project_id": self.project_id,
            "content": self.content,
            "memory_type": self.memory_type,
            "abstraction_level": self.abstraction_level,
            "pattern_type": self.pattern_type,
            "confidence_score": self.confidence_score,
            "source_memory_ids": self.source_memory_ids,
            "source_count": self.source_count,
            "tags": self.tags,
            "consolidation_method": self.consolidation_method,
            "has_embedding": self.embedding is not None,
            "reuse_count": self.reuse_count,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None,
            "consolidated_at": self.consolidated_at.isoformat() if self.consolidated_at else None,
        }
```

## Acceptance Criteria

- [ ] ConsolidatedMemory model created with all required fields
- [ ] AbstractionLevel and PatternType enums defined
- [ ] VECTOR type used for embedding column (3072 dimensions)
- [ ] PG_ARRAY used for source_memory_ids and tags
- [ ] Default values set for timestamps
- [ ] to_dict() method implemented for API responses
- [ ] Model imports without errors

## Dependencies

**Depends On**: None (foundational task)
**Blocks**: TSK-004 (Migration uses this model)
