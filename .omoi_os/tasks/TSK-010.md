---
id: TSK-010
title: Implement admin API endpoints
status: pending
ticket_id: TKT-002
parent_ticket: TKT-002
estimate: M
type: implementation
dependencies:
  depends_on:
    - TSK-007
    - TSK-008
    - TSK-009
  blocks: []
---

# TSK-010: Implement admin API endpoints

## Objective

Implement the admin API endpoints for manually triggering consolidation, checking job status, and retrieving consolidation metrics.

## Context

Admin API endpoints allow system administrators to manually control consolidation and monitor system health.

## Deliverables

- [ ] `backend/omoi_os/api/routes/admin_consolidation.py` - Admin API routes

## Implementation Notes

```python
# backend/omoi_os/api/routes/admin_consolidation.py
from typing import Dict, Any, Optional
from fastapi import APIRouter, Depends, HTTPException, status
from sqlalchemy.orm import Session

from omoi_os.models.consolidation_job import ConsolidationJob, JobStatus, TriggerType
from omoi_os.services.consolidation.trigger_service import ConsolidationTriggerService
from omoi_os.services.database import get_db
from omoi_os.api.dependencies import get_current_admin_user  # Assume this exists


router = APIRouter(prefix="/api/v1/admin", tags=["admin-consolidation"])


@router.post("/consolidate-memories", status_code=status.HTTP_202_ACCEPTED)
async def trigger_consolidation(
    project_id: str,
    trigger_type: TriggerType = TriggerType.MANUAL,
    scope: Optional[Dict[str, Any]] = None,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_admin_user)
) -> Dict[str, Any]:
    """
    Trigger a consolidation job.

    Requires admin privileges.
    """
    trigger_service = ConsolidationTriggerService(db)

    job_id = await trigger_service.trigger_consolidation(
        project_id=project_id,
        trigger_type=trigger_type,
        scope=scope,
        triggered_by=str(current_user.id)
    )

    return {
        "job_id": job_id,
        "status": "pending",
        "message": "Consolidation job queued",
        "estimated_duration_seconds": 300  # Estimate
    }


@router.get("/consolidation-status/{job_id}")
async def get_consolidation_status(
    job_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_admin_user)
) -> Dict[str, Any]:
    """Get the status of a consolidation job."""
    job = db.query(ConsolidationJob).filter_by(id=job_id).first()

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Job {job_id} not found"
        )

    total_phases = 4  # pattern_extraction, memory_merging, hierarchy_creation, playbook_integration

    return {
        "job_id": job.id,
        "status": job.status,
        "trigger_type": job.trigger_type,
        "phases_completed": job.phases_completed or [],
        "total_phases": total_phases,
        "progress": f"{len(job.phases_completed or [])}/{total_phases}" if job.phases_completed else "0/4",
        "metrics": job.metrics or {},
        "started_at": job.started_at.isoformat() if job.started_at else None,
        "completed_at": job.completed_at.isoformat() if job.completed_at else None,
        "duration_seconds": job.duration_seconds,
        "error_message": job.error_message,
        "retry_count": job.retry_count
    }


@router.get("/consolidation-metrics/{project_id}")
async def get_consolidation_metrics(
    project_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_admin_user)
) -> Dict[str, Any]:
    """Get consolidation metrics for a project."""
    from omoi_os.models.consolidated_memory import ConsolidatedMemory
    from omoi_os.models.task_memory import TaskMemory
    from sqlalchemy import func, case

    # Count memories
    total_raw = db.query(func.count(TaskMemory.id)).filter(
        TaskMemory.project_id == project_id
    ).scalar() or 0

    total_consolidated = db.query(func.count(ConsolidatedMemory.id)).filter(
        ConsolidatedMemory.project_id == project_id
    ).scalar() or 0

    # Count unconsolidated
    unconsolidated = db.query(func.count(TaskMemory.id)).filter(
        TaskMemory.project_id == project_id,
        TaskMemory.is_consolidated == False
    ).scalar() or 0

    # By abstraction level
    by_level = db.query(
        ConsolidatedMemory.abstraction_level,
        func.count(ConsolidatedMemory.id)
    ).filter(
        ConsolidatedMemory.project_id == project_id
    ).group_by(ConsolidatedMemory.abstraction_level).all()

    abstraction_dist = {str(level): count for level, count in by_level}

    # By memory type
    by_type = db.query(
        ConsolidatedMemory.memory_type,
        func.count(ConsolidatedMemory.id)
    ).filter(
        ConsolidatedMemory.project_id == project_id
    ).group_by(ConsolidatedMemory.memory_type).all()

    type_dist = {memory_type: count for memory_type, count in by_type}

    # Last job
    last_job = db.query(ConsolidationJob).filter(
        ConsolidationJob.project_id == project_id,
        ConsolidationJob.status == JobStatus.COMPLETED
    ).order_by(ConsolidationJob.completed_at.desc()).first()

    # Calculate reduction
    original_count = total_raw
    current_count = unconsolidated + total_consolidated
    reduction = ((original_count - current_count) / original_count * 100) if original_count > 0 else 0

    return {
        "project_id": project_id,
        "total_raw_memories": total_raw,
        "total_consolidated": total_consolidated,
        "unconsolidated": unconsolidated,
        "current_total": current_count,
        "reduction_percentage": round(reduction, 2),
        "last_run_time": last_job.completed_at.isoformat() if last_job else None,
        "last_run_metrics": last_job.metrics if last_job else {},
        "abstraction_distribution": abstraction_dist,
        "memory_type_distribution": type_dist
    }


@router.post("/consolidation-cancel/{job_id}")
async def cancel_consolidation_job(
    job_id: str,
    db: Session = Depends(get_db),
    current_user = Depends(get_current_admin_user)
) -> Dict[str, Any]:
    """Cancel a pending or running consolidation job."""
    job = db.query(ConsolidationJob).filter_by(id=job_id).first()

    if not job:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Job {job_id} not found"
        )

    if job.status not in [JobStatus.PENDING, JobStatus.RUNNING]:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Cannot cancel job with status {job.status}"
        )

    job.status = JobStatus.CANCELLED
    job.completed_at = datetime.now(timezone.utc)
    db.commit()

    return {
        "job_id": job.id,
        "status": "cancelled",
        "message": "Job cancelled successfully"
    }
```

## Acceptance Criteria

- [ ] POST /api/v1/admin/consolidate-memories endpoint implemented
- [ ] GET /api/v1/admin/consolidation-status/{job_id} endpoint implemented
- [ ] GET /api/v1/admin/consolidation-metrics/{project_id} endpoint implemented
- [ ] POST /api/v1/admin/consolidation-cancel/{job_id} endpoint implemented
- [ ] All endpoints require admin authentication
- [ ] OpenAPI documentation generated for all endpoints
- [ ] All tests pass

## Dependencies

**Depends On**: TSK-007 (TriggerService), TSK-008 (Engine), TSK-009 (Worker)
**Blocks**: None

## Testing

```bash
# Test endpoints
curl -X POST "http://localhost:8000/api/v1/admin/consolidate-memories?project_id=test-project" \
  -H "Authorization: Bearer $ADMIN_TOKEN"

curl -X GET "http://localhost:8000/api/v1/admin/consolidation-status/{job_id}" \
  -H "Authorization: Bearer $ADMIN_TOKEN"

curl -X GET "http://localhost:8000/api/v1/admin/consolidation-metrics/test-project" \
  -H "Authorization: Bearer $ADMIN_TOKEN"
```
