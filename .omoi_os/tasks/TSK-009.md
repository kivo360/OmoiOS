---
id: TSK-009
title: Create consolidation worker for task queue
status: pending
ticket_id: TKT-002
estimate: M
type: implementation
dependencies:
  depends_on:
    - TSK-007
    - TSK-008
  blocks:
    - TSK-010
---

# TSK-009: Create consolidation worker for task queue

## Objective

Implement the worker that processes consolidation jobs from the task queue and executes the ConsolidationEngine.

## Context

The consolidation worker receives job IDs from the task queue, updates job status, executes the engine, and records results.

## Deliverables

- [ ] `backend/omoi_os/workers/consolidation_worker.py` - Worker implementation

## Implementation Notes

```python
# backend/omoi_os/workers/consolidation_worker.py
import asyncio
import logging
from typing import Dict, Any

from sqlalchemy.orm import Session

from omoi_os.models.consolidation_job import ConsolidationJob, JobStatus
from omoi_os.services.consolidation_engine import ConsolidationEngine
from omoi_os.services.database import DatabaseService
from omoi_os.services.embedding import EmbeddingService


logger = logging.getLogger(__name__)


async def process_consolidation_job(job_id: str, db: DatabaseService) -> Dict[str, Any]:
    """
    Process a consolidation job (called by task queue worker).

    Args:
        job_id: The consolidation job ID
        db: Database service

    Returns:
        ConsolidationResult as dict
    """
    with db.get_session() as session:
        # Load job
        job = session.query(ConsolidationJob).filter_by(id=job_id).first()
        if not job:
            logger.error(f"Job {job_id} not found")
            raise ValueError(f"Job {job_id} not found")

        # Update status to running
        job.status = JobStatus.RUNNING
        job.started_at = datetime.now(timezone.utc)
        session.commit()

        logger.info(f"Starting consolidation job {job_id} for project {job.project_id}")

        try:
            # Create embedding service
            embedding_service = EmbeddingService()

            # Create engine and execute
            engine = ConsolidationEngine(
                db=session,
                embedding_service=embedding_service,
                project_id=job.project_id,
                scope=job.scope
            )

            result = await engine.execute(job_id)

            # Update job with results
            job.status = result.status
            job.completed_at = datetime.now(timezone.utc)
            job.duration_seconds = result.duration_seconds
            job.phases_completed = result.phases_completed
            job.metrics = result.metrics
            job.error_message = result.error_message

            session.commit()

            logger.info(
                f"Completed consolidation job {job_id}: "
                f"status={result.status}, "
                f"phases={len(result.phases_completed)}, "
                f"duration={result.duration_seconds}s"
            )

            # Publish event
            from omoi_os.services.event_bus import EventBusService

            try:
                event_bus = EventBusService()
                event_bus.publish(
                    event_type="consolidation.completed",
                    entity_type="consolidation_job",
                    entity_id=job_id,
                    payload={
                        "project_id": job.project_id,
                        "status": result.status,
                        "metrics": result.metrics
                    }
                )
            except Exception as e:
                logger.warning(f"Failed to publish event: {e}")

            return result.__dict__

        except Exception as e:
            logger.error(f"Consolidation job {job_id} failed: {e}", exc_info=True)

            # Update job as failed
            job.status = JobStatus.FAILED
            job.completed_at = datetime.now(timezone.utc)
            job.error_message = str(e)
            job.retry_count += 1

            session.commit()

            raise


# Register worker with task queue
def register_consolidation_worker() -> None:
    """Register consolidation worker with task queue."""
    from omoi_os.services.task_queue import TaskQueueService
    from omoi_os.services.database import get_db

    db = get_db()

    async def worker_handler(payload: Dict[str, Any]) -> None:
        job_id = payload.get("job_id")
        if not job_id:
            logger.error("No job_id in payload")
            return

        await process_consolidation_job(job_id, db)

    TaskQueueService.register_worker("consolidation", worker_handler)
    logger.info("Consolidation worker registered")
```

## Acceptance Criteria

- [ ] `process_consolidation_job` async function implemented
- [ ] Job status updated: PENDING → RUNNING → COMPLETED/FAILED
- [ ] ConsolidationEngine instantiated and executed
- [ ] Job results (status, metrics, duration) saved to database
- [ ] Events published to EventBusService
- [ ] Worker registered with TaskQueueService
- [ ] Error handling with retry count increment
- [ ] All tests pass

## Dependencies

**Depends On**: TSK-007 (TriggerService enqueues jobs), TSK-008 (Engine executes)
**Blocks**: TSK-010 (Admin API uses worker results)

## Verification

```bash
# Test worker processes a job
cd backend
python -c "
import asyncio
from omoi_os.workers.consolidation_worker import process_consolidation_job
from omoi_os.services.database import DatabaseService

async def test():
    db = DatabaseService()
    result = await process_consolidation_job('job-test-id', db)
    print(f'Result: {result}')

asyncio.run(test())
"
```
