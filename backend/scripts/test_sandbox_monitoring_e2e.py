#!/usr/bin/env python3
"""E2E test for sandbox monitoring integration.

Tests that Guardian, Conductor, and MonitoringLoop can properly
detect and monitor sandbox tasks after the sandbox migration fixes.

Prerequisites:
1. Run test_api_sandbox_spawn.py first to create a sandbox task
2. Or manually create a task with sandbox_id set

Usage:
    cd backend
    uv run python scripts/test_sandbox_monitoring_e2e.py

Test Results:
- PASS: Test validates expected behavior
- FAIL: Test found a problem
- SKIP: Test cannot run due to missing prerequisites (counts as pass but noted)
"""

import sys
from pathlib import Path
from dataclasses import dataclass
from enum import Enum

sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv

load_dotenv(Path(__file__).parent.parent / ".env.local")

from omoi_os.config import get_app_settings
from omoi_os.services.database import DatabaseService
from omoi_os.services.event_bus import EventBusService
from omoi_os.services.monitoring_loop import MonitoringLoop, MonitoringConfig
from omoi_os.services.intelligent_guardian import IntelligentGuardian
from omoi_os.services.conductor import ConductorService
from omoi_os.services.trajectory_context import TrajectoryContext
from omoi_os.services.agent_output_collector import AgentOutputCollector
from omoi_os.models.task import Task
from omoi_os.api.routes.sandbox import query_trajectory_summary


class TestResult(Enum):
    PASS = "pass"
    FAIL = "fail"
    SKIP = "skip"


@dataclass
class TestOutcome:
    result: TestResult
    message: str = ""


@dataclass
class SandboxTaskInfo:
    """Simple data class to hold task info outside of session scope."""

    id: str
    status: str
    sandbox_id: str


def test_sandbox_tasks_exist(
    db: DatabaseService,
) -> tuple[TestOutcome, list[SandboxTaskInfo]]:
    """Check for sandbox tasks in the database.

    PASS: At least one sandbox task exists (any status)
    FAIL: No sandbox tasks found - prerequisites not met
    """
    print("\n[1/7] Checking for sandbox tasks in database...")
    try:
        with db.get_session() as session:
            sandbox_tasks = (
                session.query(Task)
                .filter(Task.sandbox_id.isnot(None))
                .order_by(Task.created_at.desc())
                .limit(10)
                .all()
            )

            if not sandbox_tasks:
                print("   âŒ No sandbox tasks found in database.")
                print("   Run test_api_sandbox_spawn.py first to create one.")
                return TestOutcome(TestResult.FAIL, "No sandbox tasks in database"), []

            # Convert to simple data objects before session closes
            task_infos = [
                SandboxTaskInfo(id=str(t.id), status=t.status, sandbox_id=t.sandbox_id)
                for t in sandbox_tasks
            ]

            running_tasks = [
                t for t in task_infos if t.status in ["running", "assigned"]
            ]
            print(f"   âœ… Found {len(task_infos)} sandbox task(s) total")
            print(f"   â„¹ï¸  {len(running_tasks)} are currently running/assigned")

            for task in task_infos[:5]:
                print(
                    f"      - Task {task.id[:8]}... | Status: {task.status} | Sandbox: {task.sandbox_id[:20]}..."
                )

            return TestOutcome(TestResult.PASS), task_infos
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        return TestOutcome(TestResult.FAIL, str(e)), []


def test_monitoring_loop_detection(
    db: DatabaseService, event_bus: EventBusService, has_running_tasks: bool
) -> TestOutcome:
    """Test MonitoringLoop._get_active_sandbox_agent_ids().

    PASS: Method executes and returns expected results
    FAIL: Method throws exception OR returns wrong count
    SKIP: No running tasks to detect (but method must still work)
    """
    print("\n[2/7] Testing MonitoringLoop._get_active_sandbox_agent_ids()...")
    try:
        config = MonitoringConfig(
            guardian_interval_seconds=60,
            conductor_interval_seconds=300,
            auto_steering_enabled=False,
        )
        monitoring_loop = MonitoringLoop(db, event_bus, config)
        sandbox_ids = monitoring_loop._get_active_sandbox_agent_ids()

        print("   âœ… Method executed successfully")
        print(f"   â„¹ï¸  Found {len(sandbox_ids)} active sandbox IDs")
        for sid in sandbox_ids[:3]:
            print(f"      - {sid[:40]}...")

        if has_running_tasks and len(sandbox_ids) == 0:
            print("   âš ï¸  WARNING: Running tasks exist but none detected")
            # This is still a pass for the method - might be timing

        return TestOutcome(TestResult.PASS)
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        return TestOutcome(TestResult.FAIL, str(e))


def test_guardian_detection(
    db: DatabaseService, has_running_tasks: bool
) -> TestOutcome:
    """Test IntelligentGuardian._get_active_sandbox_agent_ids().

    PASS: Method executes successfully
    FAIL: Method throws exception
    """
    print("\n[3/7] Testing IntelligentGuardian._get_active_sandbox_agent_ids()...")
    try:
        guardian = IntelligentGuardian(db)
        sandbox_ids = guardian._get_active_sandbox_agent_ids()

        print("   âœ… Method executed successfully")
        print(f"   â„¹ï¸  Found {len(sandbox_ids)} active sandbox IDs")
        for sid in sandbox_ids[:3]:
            print(f"      - {sid[:40]}...")

        if has_running_tasks and len(sandbox_ids) == 0:
            print("   âš ï¸  WARNING: Running tasks exist but none detected")

        return TestOutcome(TestResult.PASS)
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        return TestOutcome(TestResult.FAIL, str(e))


def test_conductor_detection(
    db: DatabaseService, has_running_tasks: bool
) -> TestOutcome:
    """Test ConductorService._get_active_sandbox_agent_ids().

    PASS: Method executes successfully
    FAIL: Method throws exception
    """
    print("\n[4/7] Testing ConductorService._get_active_sandbox_agent_ids()...")
    try:
        conductor = ConductorService(db)
        with db.get_session() as session:
            sandbox_ids = conductor._get_active_sandbox_agent_ids(session)

            print("   âœ… Method executed successfully")
            print(f"   â„¹ï¸  Found {len(sandbox_ids)} active sandbox IDs")
            for sid in sandbox_ids[:3]:
                print(f"      - {sid[:40]}...")

            if has_running_tasks and len(sandbox_ids) == 0:
                print("   âš ï¸  WARNING: Running tasks exist but none detected")

            return TestOutcome(TestResult.PASS)
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        return TestOutcome(TestResult.FAIL, str(e))


def test_trajectory_context(
    db: DatabaseService, sandbox_tasks: list[SandboxTaskInfo]
) -> TestOutcome:
    """Test TrajectoryContext.get_sandbox_id_for_agent().

    NOTE: This method only returns sandbox_ids for ACTIVE (running/assigned) tasks
    because it's designed for live monitoring, not historical lookup.

    PASS: Method returns the same sandbox_id when given an active task's sandbox_id
    FAIL: Method returns wrong value or throws exception
    SKIP: No active (running/assigned) sandbox tasks to test with
    """
    print("\n[5/7] Testing TrajectoryContext.get_sandbox_id_for_agent()...")

    if not sandbox_tasks:
        print("   â­ï¸  SKIP: No sandbox tasks available for testing")
        return TestOutcome(TestResult.SKIP, "No sandbox tasks")

    # This method only works with running/assigned tasks (active monitoring)
    active_tasks = [t for t in sandbox_tasks if t.status in ["running", "assigned"]]
    if not active_tasks:
        print("   â­ï¸  SKIP: No running/assigned tasks - method requires active tasks")
        print("      (This method is for active monitoring, not historical lookups)")
        return TestOutcome(TestResult.SKIP, "No active tasks for monitoring")

    try:
        trajectory = TrajectoryContext(db)
        sandbox_id = active_tasks[0].sandbox_id

        if not sandbox_id:
            print("   â­ï¸  SKIP: Task has no sandbox_id")
            return TestOutcome(TestResult.SKIP, "Task missing sandbox_id")

        # Test: passing sandbox_id should return itself for active tasks
        result = trajectory.get_sandbox_id_for_agent(sandbox_id)

        if result == sandbox_id:
            print("   âœ… get_sandbox_id_for_agent() correctly returns sandbox_id")
            print(f"      Input:  {sandbox_id[:40]}...")
            print(f"      Output: {result[:40]}...")
            return TestOutcome(TestResult.PASS)
        else:
            print(f"   âŒ Expected: {sandbox_id[:40]}...")
            print(f"      Got:      {result}")
            return TestOutcome(TestResult.FAIL, f"Expected {sandbox_id}, got {result}")
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        return TestOutcome(TestResult.FAIL, str(e))


def test_agent_output_collector(
    db: DatabaseService,
    event_bus: EventBusService,
    sandbox_tasks: list[SandboxTaskInfo],
) -> TestOutcome:
    """Test AgentOutputCollector.get_sandbox_id_for_agent().

    NOTE: This method only returns sandbox_ids for ACTIVE (running/assigned) tasks
    because it's designed for live monitoring, not historical lookup.

    PASS: Method returns the same sandbox_id when given an active task's sandbox_id
    FAIL: Method returns wrong value or throws exception
    SKIP: No active (running/assigned) sandbox tasks to test with
    """
    print("\n[6/7] Testing AgentOutputCollector.get_sandbox_id_for_agent()...")

    if not sandbox_tasks:
        print("   â­ï¸  SKIP: No sandbox tasks available for testing")
        return TestOutcome(TestResult.SKIP, "No sandbox tasks")

    # This method only works with running/assigned tasks (active monitoring)
    active_tasks = [t for t in sandbox_tasks if t.status in ["running", "assigned"]]
    if not active_tasks:
        print("   â­ï¸  SKIP: No running/assigned tasks - method requires active tasks")
        print("      (This method is for active monitoring, not historical lookups)")
        return TestOutcome(TestResult.SKIP, "No active tasks for monitoring")

    try:
        collector = AgentOutputCollector(db, event_bus)
        sandbox_id = active_tasks[0].sandbox_id

        if not sandbox_id:
            print("   â­ï¸  SKIP: Task has no sandbox_id")
            return TestOutcome(TestResult.SKIP, "Task missing sandbox_id")

        result = collector.get_sandbox_id_for_agent(sandbox_id)

        if result == sandbox_id:
            print("   âœ… get_sandbox_id_for_agent() correctly returns sandbox_id")
            print(f"      Input:  {sandbox_id[:40]}...")
            print(f"      Output: {result[:40]}...")
            return TestOutcome(TestResult.PASS)
        else:
            print(f"   âŒ Expected: {sandbox_id[:40]}...")
            print(f"      Got:      {result}")
            return TestOutcome(TestResult.FAIL, f"Expected {sandbox_id}, got {result}")
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        return TestOutcome(TestResult.FAIL, str(e))


def test_trajectory_summary(
    db: DatabaseService, sandbox_tasks: list[SandboxTaskInfo]
) -> TestOutcome:
    """Test the trajectory summary query (excludes heartbeats).

    PASS: Query returns valid data with correct count math
    FAIL: Query throws exception OR counts don't add up
    SKIP: No sandbox tasks to test with
    """
    print("\n[7/7] Testing Trajectory Summary (heartbeat aggregation)...")

    if not sandbox_tasks:
        print("   â­ï¸  SKIP: No sandbox tasks available for testing")
        return TestOutcome(TestResult.SKIP, "No sandbox tasks")

    try:
        sandbox_id = sandbox_tasks[0].sandbox_id

        if not sandbox_id:
            print("   â­ï¸  SKIP: Task has no sandbox_id")
            return TestOutcome(TestResult.SKIP, "Task missing sandbox_id")

        result = query_trajectory_summary(db, sandbox_id, limit=50)

        total = result["total_events"]
        trajectory = result["trajectory_events"]
        heartbeats = result["heartbeat_summary"]["count"]

        print("   âœ… Trajectory summary retrieved successfully")
        print(f"      Total events:      {total}")
        print(f"      Trajectory events: {trajectory} (non-heartbeat)")
        print(f"      Heartbeats:        {heartbeats} (aggregated)")

        if heartbeats > 0:
            first_hb = result["heartbeat_summary"]["first_heartbeat"]
            last_hb = result["heartbeat_summary"]["last_heartbeat"]
            print(f"      First heartbeat:   {first_hb}")
            print(f"      Last heartbeat:    {last_hb}")

        # Verify counts add up correctly
        if trajectory + heartbeats == total:
            print(f"   âœ… Event counts verify: {trajectory} + {heartbeats} = {total}")
            return TestOutcome(TestResult.PASS)
        else:
            print(f"   âŒ Count mismatch: {trajectory} + {heartbeats} != {total}")
            return TestOutcome(
                TestResult.FAIL,
                f"Count mismatch: {trajectory} + {heartbeats} != {total}",
            )
    except Exception as e:
        print(f"   âŒ Failed: {e}")
        import traceback

        traceback.print_exc()
        return TestOutcome(TestResult.FAIL, str(e))


def main():
    print("=" * 70)
    print("SANDBOX MONITORING E2E TEST")
    print("=" * 70)

    settings = get_app_settings()
    db = DatabaseService(settings.database.url)
    event_bus = EventBusService(settings.redis.url)

    # Mask credentials in URL for display
    db_display = settings.database.url
    if "@" in db_display:
        parts = db_display.split("@")
        db_display = f"***@{parts[1]}"

    redis_display = settings.redis.url
    if "@" in redis_display:
        parts = redis_display.split("@")
        redis_display = f"***@{parts[1]}"

    print(f"\nDatabase: {db_display}")
    print(f"Redis: {redis_display}")

    results: list[tuple[str, TestOutcome]] = []

    # Test 1: Check for sandbox tasks (prerequisite for other tests)
    task_outcome, sandbox_tasks = test_sandbox_tasks_exist(db)
    results.append(("Sandbox Tasks Exist", task_outcome))

    # Determine if we have running tasks for detection tests
    has_running_tasks = any(t.status in ["running", "assigned"] for t in sandbox_tasks)

    # Tests 2-4: Detection methods (should work even without running tasks)
    results.append(
        (
            "MonitoringLoop Detection",
            test_monitoring_loop_detection(db, event_bus, has_running_tasks),
        )
    )
    results.append(
        ("Guardian Detection", test_guardian_detection(db, has_running_tasks))
    )
    results.append(
        ("Conductor Detection", test_conductor_detection(db, has_running_tasks))
    )

    # Tests 5-7: Require sandbox tasks to test properly
    results.append(("TrajectoryContext", test_trajectory_context(db, sandbox_tasks)))
    results.append(
        (
            "AgentOutputCollector",
            test_agent_output_collector(db, event_bus, sandbox_tasks),
        )
    )
    results.append(("Trajectory Summary", test_trajectory_summary(db, sandbox_tasks)))

    # Print summary
    print("\n" + "=" * 70)
    print("TEST SUMMARY")
    print("=" * 70)

    passed = 0
    failed = 0
    skipped = 0

    for test_name, outcome in results:
        if outcome.result == TestResult.PASS:
            status = "âœ… PASS"
            passed += 1
        elif outcome.result == TestResult.FAIL:
            status = "âŒ FAIL"
            failed += 1
        else:  # SKIP
            status = "â­ï¸  SKIP"
            skipped += 1

        if outcome.message:
            print(f"   {status}: {test_name} ({outcome.message})")
        else:
            print(f"   {status}: {test_name}")

    print("\n" + "-" * 70)
    print(
        f"   Total: {len(results)} | Passed: {passed} | Failed: {failed} | Skipped: {skipped}"
    )

    if failed == 0:
        if skipped > 0:
            print(f"\nâœ… ALL TESTS PASSED ({skipped} skipped)")
            print("   Some tests were skipped due to missing prerequisites.")
        else:
            print("\nğŸ‰ ALL TESTS PASSED!")
            print("   Sandbox monitoring systems are working correctly.")
    else:
        print(f"\nâš ï¸  {failed} test(s) failed. Check the output above for details.")

    print("=" * 70)

    return failed == 0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
