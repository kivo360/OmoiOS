llm:
  model: openai/glm-4.6
  api_key: 009332196c644810b859e88f26d28fe3.a9dfM8z1qQDWCpiN
  base_url: https://api.z.ai/api/coding/paas/v4
  # fireworks_api_key loaded from LLM_FIREWORKS_API_KEY env var

database:
  # Remote Railway PostgreSQL database (default)
  url: postgresql+psycopg://postgres:YFee-Rwr9VMfze8Y~SYhMLNhPXkNbXsp@trolley.proxy.rlwy.net:56037/railway

redis:
  # Remote Railway Redis instance (default)
  url: redis://default:qPwXIhWmwvfdBLgVrIIihMUHGoSJFHqg@crossover.proxy.rlwy.net:23902

task_queue:
  age_ceiling: 3600
  sla_urgency_window: 900
  starvation_limit: 7200
  blocker_ceiling: 10
  w_p: 0.45
  w_a: 0.2
  w_d: 0.15
  w_b: 0.15
  w_r: 0.05
  sla_boost_multiplier: 1.25
  starvation_floor_score: 0.6

approval:
  ticket_human_review: false
  approval_timeout_seconds: 1800
  on_reject: delete

supabase:
  url: null
  anon_key: null
  service_role_key: null
  db_url: null

auth:
  jwt_secret_key: dev-secret-key-change-in-production
  jwt_algorithm: HS256
  access_token_expire_minutes: 15
  refresh_token_expire_days: 7
  min_password_length: 8
  require_uppercase: true
  require_lowercase: true
  require_digit: true
  require_special_char: false
  max_login_attempts: 5
  login_attempt_window_minutes: 15
  session_expire_days: 30

  # OAuth provider credentials (set via env vars: AUTH_GITHUB_CLIENT_ID, etc.)
  github_client_id: null
  github_client_secret: null
  google_client_id: null
  google_client_secret: null
  gitlab_client_id: null
  gitlab_client_secret: null
  gitlab_base_url: https://gitlab.com

  # OAuth redirect URI (frontend callback URL)
  # This is where the frontend receives the OAuth callback after authentication
  # The backend converts this to: http://localhost:18000/api/v1/auth/oauth/{provider}/callback
  # for the actual OAuth provider callback URL
  # Can be overridden with AUTH_OAUTH_REDIRECT_URI environment variable
  oauth_redirect_uri: http://localhost:3000/callback

workspace:
  root: ./workspaces
  worker_dir: /tmp/omoi_os_workspaces
  mode: local
  docker_base_image: nikolaik/python-nodejs:python3.12-nodejs22

monitoring:
  guardian_interval_seconds: 60
  conductor_interval_seconds: 300
  health_check_interval_seconds: 30
  auto_steering_enabled: false
  max_concurrent_analyses: 5

diagnostic:
  enabled: false  # DISABLED - runaway loop detected, see sandbox_lifecycle_state_machine.md
  cooldown_seconds: 60
  min_stuck_time_seconds: 60
  max_agents_to_analyze: 15
  max_conductor_analyses: 5
  max_tasks_per_run: 5

worker:
  concurrency: 2

daytona:
  api_key: ${DAYTONA_API_KEY}
  api_url: https://app.daytona.io/api
  target: us
  image: nikolaik/python-nodejs:python3.12-nodejs22
  snapshot: claude-agent-sdk-medium  # Default snapshot for sandbox creation
  timeout: 300
  # Sandbox resource limits (for preventing OOM kills)
  sandbox_memory_gb: 4  # Memory in GiB (max: 8)
  sandbox_cpu: 2  # CPU cores (max: 4)
  sandbox_disk_gb: 8  # Disk space in GiB (max: 10)

integrations:
  mcp_server_url: http://localhost:18000/mcp
  enable_mcp_tools: true
  github_token: null

embedding:
  provider: fireworks
  fireworks_api_key: ${EMBEDDING_FIREWORKS_API_KEY}
  openai_api_key: null
  model_name: fireworks/qwen3-embedding-8b
  # Dimensions for embeddings - must be <= 2000 for pgvector standard indexing
  dimensions: 1536
  # Cache directory for local model files (prevents re-downloading on each start)
  # Defaults to ~/.cache/fastembed if null
  cache_dir: ~/.cache/omoi_os/models
  # Lazy loading defers model initialization until first embedding request
  lazy_load: true
  # Preload model in background thread at startup (only if lazy_load is true)
  preload_in_background: true

observability:
  enable_tracing: false
  logfire_token: null

title_generation:
  # Model for generating task titles (lightweight, cheap model)
  # Can be overridden with TITLE_GEN_MODEL environment variable
  model: accounts/fireworks/models/gpt-oss-20b
  # API key - defaults to LLM_FIREWORKS_API_KEY if not set
  # Can be overridden with TITLE_GEN_API_KEY environment variable
  api_key: null
  # Base URL for the LLM provider
  # Can be overridden with TITLE_GEN_BASE_URL environment variable
  base_url: https://api.fireworks.ai/inference/v1

demo:
  sdk_example: activate_skill
  persistence_dir: ./.conversations
  add_security_analyzer: false
  confirm_all: true

billing:
  # Currency for payments (ISO 4217)
  currency: usd

  # Workflow pricing ($10 per workflow completion)
  workflow_price_usd: 10.0

  # Free tier: workflows per month before billing starts
  free_workflows_per_month: 5

  # Minimum credit purchase in USD
  min_credit_purchase_usd: 10.0

  # Maximum credit purchase in USD (single transaction)
  max_credit_purchase_usd: 1000.0

  # Stripe URLs for checkout redirects
  # Override via STRIPE_SUCCESS_URL, STRIPE_CANCEL_URL, STRIPE_PORTAL_RETURN_URL env vars
  success_url: http://localhost:3000/billing/success
  cancel_url: http://localhost:3000/billing/cancel
  portal_return_url: http://localhost:3000/billing

  # Stripe API keys (MUST be set via environment variables for security)
  # STRIPE_API_KEY - Secret key (sk_test_... or sk_live_...)
  # STRIPE_PUBLISHABLE_KEY - Publishable key (pk_test_... or pk_live_...)
  # STRIPE_WEBHOOK_SECRET - Webhook signing secret (whsec_...)

