# Phase 4 Parallel Implementation Plan

**Purpose**: Outline the parallel execution strategy, squad assignments, deliverables, and integration points for Phase 4 Monitoring & Observability implementation.
**Related**: docs/migrations/versions/005_monitoring_observability.py, docs/monitoring/metrics.md, docs/observability/setup.md, docs/alerting/rules.md, docs/watchdog/policies.md, docs/architecture/phase3_telemetry.md

---


**Created**: 2025-11-17  
**Status**: ACTIVE  
**Target**: Complete Phase 4 (Monitoring & Observability) in parallel execution

---

## Parallel Execution Strategy

### Timeline Overview

**Week 7 (Days 1-5):**
- Day 1-2: Monitor + Observability Squads start (parallel, independent)
- Day 3-5: Alerting + Watchdog Squads start (consume Monitor outputs)

**Week 8 (Days 1-5):**
- Day 1-3: All squads integrate and resolve cross-dependencies
- Day 4-5: Game-day validation (anomaly ‚Üí alert ‚Üí remediation loop)

---

## Squad Assignments

### üîµ **Monitor Squad** (Can Start: Day 1)
**Dependencies:** Phase 3 telemetry (‚úÖ already emitting)  
**Blocks:** Alerting Squad (needs metrics schema)

**Deliverables:**
1. ‚úÖ Monitor models (MonitorAnomaly, Alert) ‚Äî DONE
2. ‚úÖ MonitorService with metrics collection ‚Äî DONE
3. ‚úÖ Telemetry contracts (`omoi_os/telemetry/`) ‚Äî DONE
4. ‚è≥ Dashboard API routes (`/api/v1/monitor`)
5. ‚è≥ Anomaly detection refinement (rolling p95, trend analysis)
6. ‚è≥ Tests: `test_monitor.py` (metric collection, anomaly detection)

**Hand-offs:**
- Metrics schema ‚Üí Alerting Squad (Day 2)
- Anomaly events ‚Üí Watchdog Squad (Day 3)

---

### üü¢ **Observability Squad** (Can Start: Day 1, fully independent)
**Dependencies:** None  
**Blocks:** None (parallel stream)

**Deliverables:**
1. ‚è≥ OpenTelemetry integration (traces for service calls)
2. ‚è≥ Structured logging setup (JSON logs with correlation IDs)
3. ‚è≥ Performance profiling hooks
4. ‚è≥ Log aggregation pipeline
5. ‚è≥ Tests: `test_observability.py`

**Output:**
- Trace context propagation across services
- Structured logs ready for ELK/Loki
- Performance profiles for optimization

---

### üü° **Alerting Squad** (Can Start: Day 3, needs Monitor)
**Dependencies:** Monitor metrics schema (2-day delay)  
**Blocks:** Watchdog Squad (needs alert events)

**Deliverables:**
1. ‚è≥ AlertService with rule evaluation engine
2. ‚è≥ Alert rule definitions (YAML configs)
3. ‚è≥ Routing adapters (email/Slack/webhook mocks)
4. ‚è≥ Alert API routes (`/api/v1/alerts`)
5. ‚è≥ Tests: `test_alerting.py`, `test_alert_rules.py`

**Hand-offs:**
- Alert events (`monitor.alert.triggered`) ‚Üí Watchdog Squad
- Alert payload schema ‚Üí shared telemetry config

---

### üî¥ **Watchdog Squad** (Can Start: Day 3, needs Alerting + Registry)
**Dependencies:** Alert events (Day 3), Phase 3 Registry APIs (‚úÖ exists)  
**Blocks:** None (end of chain)

**Deliverables:**
1. ‚è≥ WatchdogService with remediation policies
2. ‚è≥ Policy definitions (YAML: restart, failover, escalate)
3. ‚è≥ Registry integration (mark unhealthy, request replacement)
4. ‚è≥ Watchdog API routes (`/api/v1/watchdog`)
5. ‚è≥ Tests: `test_watchdog.py`, `test_remediation.py`

**Output:**
- Automated remediation (agent restart, task reassignment)
- Escalation to Guardian agent (Phase 5 hook)

---

## Shared Infrastructure (Already Created ‚úÖ)

### Telemetry Contracts
- ‚úÖ `omoi_os/telemetry/__init__.py` ‚Äî Metric/Alert DTOs, standard metrics catalog
- ‚úÖ `omoi_os/models/monitor_anomaly.py` ‚Äî MonitorAnomaly, Alert models
- ‚úÖ `omoi_os/services/monitor.py` ‚Äî MonitorService skeleton

### Event Types (To Be Published)
- `monitor.anomaly.detected` ‚úÖ
- `monitor.alert.triggered` ‚è≥
- `monitor.alert.acknowledged` ‚è≥
- `monitor.alert.resolved` ‚è≥
- `watchdog.remediation.started` ‚è≥
- `watchdog.remediation.completed` ‚è≥

---

## Migration Strategy

### Migration 005: Monitoring Tables
**File:** `migrations/versions/005_monitoring_observability.py`  
**Parent:** `004_collaboration_and_locking`

**Tables to Create:**
- `monitor_anomalies` (Monitor Squad)
- `alerts` (Alerting Squad)
- `alert_rules` (Alerting Squad)
- `watchdog_actions` (Watchdog Squad)
- `trace_spans` (Observability Squad, optional if using external APM)

---

## Integration Points

### Monitor ‚Üí Alerting
**Contract:** Metrics API endpoint returns `List[MetricSample]`

```python
GET /api/v1/monitor/metrics?phase_id=PHASE_IMPLEMENTATION
Response: [
  {
    "metric_name": "tasks_queued_total",
    "value": 15,
    "labels": {"phase_id": "PHASE_IMPLEMENTATION"},
    "timestamp": "2025-11-17T01:00:00Z"
  }
]
```

**Integration Test:** Alerting can poll Monitor API and evaluate rules

---

### Alerting ‚Üí Watchdog
**Contract:** Alert events on EventBus

```python
SystemEvent(
    event_type="monitor.alert.triggered",
    entity_type="alert",
    entity_id="alert-123",
    payload={
        "rule_id": "high_queue_depth",
        "severity": "warning",
        "metric_name": "tasks_queued_total",
        "current_value": 50,
        "threshold": 20,
        "labels": {"phase_id": "PHASE_IMPLEMENTATION"}
    }
)
```

**Integration Test:** Watchdog subscribes to alert events and triggers remediation

---

### Monitor/Alerting ‚Üí Observability
**Contract:** Trace context in service calls

```python
# Every service method call includes trace context
with tracer.start_span("monitor.collect_metrics") as span:
    span.set_attribute("phase_id", phase_id)
    metrics = monitor.collect_task_metrics(phase_id)
```

**Integration Test:** End-to-end trace captured across service boundaries

---

## Test Strategy

### Unit Tests (Per Squad)
- Monitor: Metric collection accuracy, anomaly detection logic
- Alerting: Rule evaluation, severity escalation, deduplication
- Watchdog: Policy selection, remediation actions, idempotency
- Observability: Trace propagation, log formatting, correlation IDs

### Integration Tests (Cross-Squad)
- Monitor metrics ‚Üí Alerting rules ‚Üí Alert events ‚úÖ
- Alert events ‚Üí Watchdog ‚Üí Remediation action ‚úÖ
- All services ‚Üí Observability ‚Üí Complete trace ‚úÖ

### Game-Day Scenario
1. Inject high queue depth ‚Üí Monitor detects anomaly
2. Anomaly triggers alert rule ‚Üí Alerting fires event
3. Watchdog receives alert ‚Üí Spawns additional worker
4. Observability captures full trace ‚Üí Verify end-to-end

---

## Files to Create (30+ files)

### Monitor Squad (7 files)
- ‚úÖ `omoi_os/models/monitor_anomaly.py`
- ‚úÖ `omoi_os/services/monitor.py`
- ‚úÖ `omoi_os/telemetry/__init__.py`
- ‚è≥ `omoi_os/api/routes/monitor.py`
- ‚è≥ `tests/test_monitor.py`
- ‚è≥ `tests/test_anomaly_detection.py`
- ‚è≥ `docs/monitoring/metrics.md`

### Observability Squad (8 files)
- ‚è≥ `omoi_os/observability/__init__.py`
- ‚è≥ `omoi_os/observability/tracing.py`
- ‚è≥ `omoi_os/observability/logging.py`
- ‚è≥ `omoi_os/observability/profiling.py`
- ‚è≥ `tests/test_tracing.py`
- ‚è≥ `tests/test_logging.py`
- ‚è≥ `tests/test_profiling.py`
- ‚è≥ `docs/observability/setup.md`

### Alerting Squad (10 files)
- ‚è≥ `omoi_os/models/alert_rule.py`
- ‚è≥ `omoi_os/services/alerting.py`
- ‚è≥ `omoi_os/services/routing.py` (email/Slack/webhook adapters)
- ‚è≥ `omoi_os/api/routes/alerts.py`
- ‚è≥ `omoi_os/config/alert_rules/*.yaml` (3 example rules)
- ‚è≥ `tests/test_alerting.py`
- ‚è≥ `tests/test_alert_rules.py`
- ‚è≥ `tests/test_routing.py`
- ‚è≥ `docs/alerting/rules.md`

### Watchdog Squad (8 files)
- ‚è≥ `omoi_os/models/watchdog_action.py`
- ‚è≥ `omoi_os/services/watchdog.py`
- ‚è≥ `omoi_os/config/watchdog_policies/*.yaml`
- ‚è≥ `omoi_os/api/routes/watchdog.py`
- ‚è≥ `tests/test_watchdog.py`
- ‚è≥ `tests/test_remediation.py`
- ‚è≥ `tests/test_watchdog_policies.py`
- ‚è≥ `docs/watchdog/policies.md`

### Shared (3 files)
- ‚è≥ `migrations/versions/005_monitoring_observability.py`
- ‚è≥ `tests/test_phase4_integration.py`
- ‚è≥ `scripts/game_day_scenario.py`

**Total:** ~35 files (~2,000 lines of code)

---

## Current Progress

‚úÖ **Completed (This Session):**
- Telemetry contracts and metric definitions
- Monitor models (MonitorAnomaly, Alert)
- MonitorService skeleton with metrics collection
- Anomaly detection algorithm (rolling statistics)

‚è≥ **Next Steps:**
1. Complete Monitor API routes and tests
2. Start Observability tracing integration (parallel)
3. Implement Alerting service (after Monitor metrics schema solidified)
4. Implement Watchdog service (after Alerting events schema solidified)

---

## Coordination Checkpoints

### Day 2 Sync
- Monitor Squad: Publish metrics API contract
- Observability Squad: Share trace context propagation pattern
- Review: Does alerting squad have what they need?

### Day 4 Sync
- Alerting Squad: Publish alert event schema
- Monitor + Observability: Integration test results
- Review: Does watchdog squad have what they need?

### Day 6 Sync
- All Squads: Cross-integration test results
- Prepare game-day scenario script
- Review: Any blocking issues?

### Day 8 Sync
- Game-day validation complete
- Documentation review
- Phase 4 sign-off

---

## Risk Mitigation

### Risks
1. **Schema Mismatch:** Monitor/Alerting/Watchdog use incompatible formats
2. **Event Lag:** EventBus latency causes delayed remediation
3. **Test Interference:** Parallel test runs conflict on shared DB
4. **Merge Conflicts:** Multiple agents modify same files

### Mitigations
1. ‚úÖ Shared `telemetry/` module with DTOs (already created)
2. Use contract tests before integration
3. Separate test databases per squad (different DB names)
4. Coordinate on file ownership (Monitor owns monitor.py, etc.)

---

## Success Criteria

### Phase 4 Complete When:
- [ ] All 4 squad deliverables implemented
- [ ] 40+ new tests passing (10 per squad)
- [ ] Zero linting errors
- [ ] Migration 005 applied successfully
- [ ] Game-day scenario passes end-to-end
- [ ] Documentation complete (4 squad docs + integration guide)

**Expected Outcome:**
- Real-time monitoring dashboard
- Automated alerting with routing
- Self-healing via watchdog remediation
- Full observability with traces/logs/metrics

---

**Ready to proceed:** ‚úÖ YES  
**Blocking issues:** ‚úÖ NONE  
**Go/No-Go Decision:** ‚úÖ GO FOR PARALLEL EXECUTION

